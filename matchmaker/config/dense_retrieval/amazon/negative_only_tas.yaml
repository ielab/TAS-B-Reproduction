expirement_base_path: "/scratch/project/neural_ir/dylan/balance_training/TAS-query-original"

trained_model: /scratch/project/neural_ir/dylan/balance_training/TAS-query-original/2023-02-12_1122_negative_only_tas-amazon_data

collection_tsv: "/scratch/project/neural_ir/dylan/balance_training/esci-data-main/shopping_queries_dataset/collection_amazon.tsv"

collection_batch_size: 2048
query_batch_size: 48

onnx_use_inference: False
dataloader_num_workers: 10 # 0 means only using the main thread (not recommended)

query_sets:
  <msmarco>:
    queries_tsv: "/scratch/project/neural_ir/dylan/balance_training/esci-data-main/shopping_queries_dataset/queries_test_amazon.tsv"
    qrels: "/scratch/project/neural_ir/dylan/balance_training/esci-data-main/shopping_queries_dataset/qrels.test_amazon.tsv"
    binarization_point: 1 # what minimum relevant grade to assume for binarized metrics (mrr, recall ...)
    top_n: 1000 # how many results to return

#  <name_of_set2...>: # optional more than 1 query sets
#    queries_tsv: <TODO: path to a single .tsv file with id<tab>text>
#    qrels: <TODO: path to a trec-style qrels file>
#    binarization_point: 1 # what minimum relevant grade to assume for binarized metrics (mrr, recall ...)
#    top_n: 100 # how many results to return

# settings for storing vectors
token_block_size: 50000 # every n vectors create a new numpy memory mapped array file
token_dim: 768 # sets the output dimension of the model
token_dtype: "float16" # sets the dtype (either float16 or float32)

#
# general index
#
faiss_index_type: "hnsw" # or full,ivf,hnsw,scann
faiss_use_gpu: True

#
# hnsw settings
#
faiss_hnsw_graph_neighbors: 128
faiss_hnsw_efConstruction: 128 # higher is more accurate and slower to construct
faiss_hnsw_efSearch: 128

#
# ivf settings
#
faiss_ivf_search_probe_count: 500
faiss_ivf_list_count: 2000


